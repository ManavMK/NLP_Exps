{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "serial-proceeding",
      "metadata": {
        "id": "serial-proceeding"
      },
      "source": [
        "# Experiment 03"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YSoaOy8QrRtI",
      "metadata": {
        "id": "YSoaOy8QrRtI"
      },
      "source": [
        "**27_Manav_Kawale_NLP_CSE(DS)**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exposed-trinity",
      "metadata": {
        "id": "exposed-trinity"
      },
      "source": [
        "### Library required"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "explicit-leather",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "explicit-leather",
        "outputId": "cc52791b-11cc-4e76-b423-f1b4603f78f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "parliamentary-transcript",
      "metadata": {
        "id": "parliamentary-transcript"
      },
      "source": [
        "### Text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "centered-aurora",
      "metadata": {
        "id": "centered-aurora"
      },
      "outputs": [],
      "source": [
        "text = 'The general trend in IR systems over time has been from standard use of quite large stop lists (200-300 terms) to very small stop lists (7-12 terms) to no stop list whatsoever. Web search engines generally do not use stop lists.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "configured-brass",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "configured-brass",
        "outputId": "561704af-2f10-4389-9f0c-41d53f9efc0e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'TON 618 is a hyperluminous, broad-absorption-line, radio-loud quasar and Lyman-alpha blob located near the border of the constellations Canes Venatici and Coma Berenices, with the projected comoving distance of approximately 18.2 billion light-years from Earth.'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tamil-technical",
      "metadata": {
        "id": "tamil-technical"
      },
      "source": [
        "### Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "damaged-digit",
      "metadata": {
        "id": "damaged-digit"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YK9_DqNEnppo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YK9_DqNEnppo",
        "outputId": "16c68daf-ecfb-4082-8a0b-6cf705c2b821"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "through-symposium",
      "metadata": {
        "id": "through-symposium"
      },
      "outputs": [],
      "source": [
        "stop_words = stopwords.words('english')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "authentic-answer",
      "metadata": {
        "id": "authentic-answer"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "words = word_tokenize(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "functional-checkout",
      "metadata": {
        "id": "functional-checkout"
      },
      "source": [
        "#### Applying stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "piano-graph",
      "metadata": {
        "id": "piano-graph"
      },
      "outputs": [],
      "source": [
        "holder = list()\n",
        "for w in words:\n",
        "    if w not in set(stop_words):\n",
        "        holder.append(w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accompanied-queens",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "accompanied-queens",
        "outputId": "8ee4ed79-3760-42c6-bb99-406446064ce4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['The',\n",
              " 'general',\n",
              " 'trend',\n",
              " 'IR',\n",
              " 'systems',\n",
              " 'time',\n",
              " 'standard',\n",
              " 'use',\n",
              " 'quite',\n",
              " 'large',\n",
              " 'stop',\n",
              " 'lists',\n",
              " '(',\n",
              " '200-300',\n",
              " 'terms',\n",
              " ')',\n",
              " 'small',\n",
              " 'stop',\n",
              " 'lists',\n",
              " '(',\n",
              " '7-12',\n",
              " 'terms',\n",
              " ')',\n",
              " 'stop',\n",
              " 'list',\n",
              " 'whatsoever',\n",
              " '.',\n",
              " 'Web',\n",
              " 'search',\n",
              " 'engines',\n",
              " 'generally',\n",
              " 'use',\n",
              " 'stop',\n",
              " 'lists',\n",
              " '.']"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "holder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "digital-henry",
      "metadata": {
        "id": "digital-henry"
      },
      "source": [
        "#### List Comprehension for stop words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "environmental-cartridge",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "environmental-cartridge",
        "outputId": "e5dcdb34-6050-40b1-edf3-ef8cd5b6b456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['The', 'general', 'trend', 'IR', 'systems', 'time', 'standard', 'use', 'quite', 'large', 'stop', 'lists', '(', '200-300', 'terms', ')', 'small', 'stop', 'lists', '(', '7-12', 'terms', ')', 'stop', 'list', 'whatsoever', '.', 'Web', 'search', 'engines', 'generally', 'use', 'stop', 'lists', '.']\n"
          ]
        }
      ],
      "source": [
        "holder = [w for w in words if w not in set(stop_words)]\n",
        "print(holder)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "forty-worth",
      "metadata": {
        "id": "forty-worth"
      },
      "source": [
        "### Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "related-costs",
      "metadata": {
        "id": "related-costs"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "unsigned-mobile",
      "metadata": {
        "id": "unsigned-mobile"
      },
      "outputs": [],
      "source": [
        "porter = PorterStemmer()\n",
        "snow = SnowballStemmer(language = 'english')\n",
        "lancaster = LancasterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ready-inside",
      "metadata": {
        "id": "ready-inside"
      },
      "outputs": [],
      "source": [
        "words = ['play', 'plays', 'played', 'playing', 'player']"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "prostate-commitment",
      "metadata": {
        "id": "prostate-commitment"
      },
      "source": [
        "#### Porter Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "involved-cherry",
      "metadata": {
        "id": "involved-cherry"
      },
      "outputs": [],
      "source": [
        "porter_stemmed = list()\n",
        "for w in words:\n",
        "    stemmed_words = porter.stem(w)\n",
        "    porter_stemmed.append(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "narrative-auditor",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "narrative-auditor",
        "outputId": "91f54ee7-2628-45a2-9c13-a406c449755b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['play', 'play', 'play', 'play', 'player']"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "porter_stemmed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mobile-giant",
      "metadata": {
        "id": "mobile-giant"
      },
      "source": [
        "#### Porter Stemmer List Comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "juvenile-assets",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juvenile-assets",
        "outputId": "225c11a1-348f-4aaa-86b1-da27ccd03936"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['play', 'play', 'play', 'play', 'player']\n"
          ]
        }
      ],
      "source": [
        "porter_stemmed = [porter.stem(x) for x in words]\n",
        "print (porter_stemmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "japanese-piece",
      "metadata": {
        "id": "japanese-piece"
      },
      "source": [
        "#### Snowball Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skilled-coordinate",
      "metadata": {
        "id": "skilled-coordinate"
      },
      "outputs": [],
      "source": [
        "snow_stemmed = list()\n",
        "for w in words:\n",
        "    stemmed_words = snow.stem(w)\n",
        "    snow_stemmed.append(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "compressed-constitution",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "compressed-constitution",
        "outputId": "df66dbb3-5f75-4635-864d-a87da27df7e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['play', 'play', 'play', 'play', 'player']"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "snow_stemmed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "handled-preparation",
      "metadata": {
        "id": "handled-preparation"
      },
      "source": [
        "#### Snowball Stemmer List Comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aboriginal-checklist",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aboriginal-checklist",
        "outputId": "9891a678-443b-4be1-95e8-a0404edf9c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['play', 'play', 'play', 'play', 'player']\n"
          ]
        }
      ],
      "source": [
        "snow_stemmed = [snow.stem(x) for x in words]\n",
        "print (snow_stemmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "narrative-graduation",
      "metadata": {
        "id": "narrative-graduation"
      },
      "source": [
        "#### Lancaster Stemmer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "gorgeous-omega",
      "metadata": {
        "id": "gorgeous-omega"
      },
      "outputs": [],
      "source": [
        "lancaster_stemmed = list()\n",
        "for w in words:\n",
        "    stemmed_words = lancaster.stem(w)\n",
        "    lancaster_stemmed.append(stemmed_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "funded-draft",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "funded-draft",
        "outputId": "206a25a8-c4c9-418b-b5ae-b340ea5d7655"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['play', 'play', 'play', 'play', 'play']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lancaster_stemmed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "stupid-jordan",
      "metadata": {
        "id": "stupid-jordan"
      },
      "source": [
        "#### Lancaster Stemmer List Comprehension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "seven-world",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seven-world",
        "outputId": "04a365ad-5359-4e10-9e81-2c6abc4756f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['play', 'play', 'play', 'play', 'play']\n"
          ]
        }
      ],
      "source": [
        "lancaster_stemmed = [lancaster.stem(x) for x in words]\n",
        "print (lancaster_stemmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wanted-wallace",
      "metadata": {
        "id": "wanted-wallace"
      },
      "source": [
        "### Lemmatization : This has a more expansive vocabulary than Stemming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "coated-sport",
      "metadata": {
        "id": "coated-sport"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "impressed-switzerland",
      "metadata": {
        "id": "impressed-switzerland"
      },
      "outputs": [],
      "source": [
        "lemmatized = [wordnet.lemmatize(x) for x in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "removed-company",
      "metadata": {
        "id": "removed-company",
        "outputId": "ad9e0d1c-5abb-4180-be76-1b4884146127"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['play', 'play', 'played', 'playing', 'player']"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lemmatized"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
